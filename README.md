---

# An√°lise de Classifica√ß√£o e Estabilidade de Modelo com Dataset Pima Diabetes

Este reposit√≥rio cont√©m uma an√°lise aprofundada do dataset "Pima Indians Diabetes". O notebook foca n√£o apenas na classifica√ß√£o, mas na investiga√ß√£o da **estabilidade e confiabilidade** das m√©tricas de avalia√ß√£o do modelo.

Esta √© a **nova vers√£o**, mais detalhada, de um projeto de pesquisa apresentado no congresso **UMC Summit**.

## üèÖ Vers√£o do Congresso (Vers√£o Antiga)

A vers√£o original deste projeto, que foi formatada e apresentada no congresso (e est√° vinculada ao QR code da apresenta√ß√£o), est√° dispon√≠vel no link abaixo.

‚û°Ô∏è **Reposit√≥rio do Congresso (Vers√£o Antiga): [https://github.com/ArthurS357/Collab](https://github.com/ArthurS357/Collab)**

O notebook *deste* reposit√≥rio (`Pima_Indians_Diabetes.ipynb`) √© a **vers√£o nova e atualizada**, contendo uma an√°lise mais aprofundada.

---

## üöÄ Objetivos do Estudo Atual

O notebook *deste* reposit√≥rio (`Pima_Indians_Diabetes.ipynb`) foca em:

1.  **Limpeza e Prepara√ß√£o:** Realizar um pr√©-processamento robusto dos dados, tratando valores ausentes (representados por '0') e outliers (usando IQR).
2.  **Modelagem SVM:** Treinar e otimizar um modelo de Support Vector Machine (SVM) com kernel `rbf`.
3.  **An√°lise de Estabilidade:** Comparar a vari√¢ncia e a confiabilidade da acur√°cia usando `K-Fold` padr√£o contra o `Repeated Stratified K-Fold`.

## üõ†Ô∏è Tecnologias e Bibliotecas

* **Python**
* **Pandas** (para manipula√ß√£o de dados)
* **Scikit-learn (sklearn)** (para pr√©-processamento, modelagem e avalia√ß√£o)
* **Matplotlib / Seaborn** (para visualiza√ß√£o de dados)

## üìà Metodologia e Pipeline

O notebook segue um pipeline estruturado em 5 fases:

1.  **Carga e Configura√ß√£o:** Carregamento do dataset e tratamento inicial de valores nulos (zeros).
2.  **An√°lise Explorat√≥ria (EDA):** Investiga√ß√£o da distribui√ß√£o dos dados.
3.  **Pr√©-processamento:**
    * Tratamento de outliers com base no m√©todo IQR.
    * Padroniza√ß√£o dos dados com `StandardScaler`.
4.  **Modelagem (SVM):**
    * Uso do `GridSearchCV` para encontrar os melhores hiperpar√¢metros (C=10, gamma=0.01).
    * Treinamento do modelo `SVC` final.
5.  **Avalia√ß√£o de Estabilidade:**
    * Execu√ß√£o do `K-Fold` (10 splits).
    * Execu√ß√£o do `Repeated Stratified K-Fold` (10 splits, 3 repeti√ß√µes).

## üìä Resultados e Conclus√£o (Deste Notebook)

* **Desempenho do Modelo:** O modelo SVM otimizado alcan√ßou uma acur√°cia de **81.17%** nos dados de teste.
* **Estabilidade da Valida√ß√£o:** A an√°lise de valida√ß√£o cruzada demonstrou que o `Repeated Stratified K-Fold` √© uma m√©trica mais est√°vel:
    * **K-Fold (10 splits):** Acur√°cia M√©dia de 79.94% (std: 0.05).
    * **Repeated K-Fold (10 splits, 3 repeats):** Acur√°cia M√©dia de 80.09% (std: 0.04).

A conclus√£o √© que, embora as m√©dias sejam similares, o **`Repeated Stratified K-Fold`** oferece uma estimativa de desempenho mais confi√°vel e com menor vari√¢ncia (desvio padr√£o menor), sendo prefer√≠vel para avaliar a real capacidade de generaliza√ß√£o do modelo.
